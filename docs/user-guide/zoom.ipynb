{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Zoom Polarization Analysis\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import plopp\n",
    "import sciline\n",
    "import scipp as sc\n",
    "from ess import polarization as pol\n",
    "from ess import sans\n",
    "from ess import isissans as isis\n",
    "import ess.isissans.data  # noqa: F401\n",
    "from ess.sans.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_folder = Path('zoom-data-2025-07')\n",
    "# Runs with analyzer at 4 different times\n",
    "cell_runs = [\n",
    "    str(data_folder / '3He_unpolarized_in' / f'ZOOM00038{run}.nxs')\n",
    "    for run in [423, 425, 427, 429, 431, 433, 435, 437]\n",
    "]\n",
    "empty_run = data_folder / 'Background_files' / 'ZOOM00038336.nxs'\n",
    "depolarized_run = data_folder / 'Background_files' / 'ZOOM00038470.nxs'\n",
    "cell_runs = [*cell_runs, depolarized_run]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Setup SANS workflow for computing transmission fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    WavelengthBins: sc.geomspace(\n",
    "        'wavelength', start=1.75, stop=16.5, num=141, unit='Ã…'\n",
    "    ),\n",
    "    isis.mantidio.CalibrationWorkspace: None,\n",
    "    # Spectrum numbers used for histogram files (Workspace2D)\n",
    "    isis.MonitorSpectrumNumber[Incident]: isis.MonitorSpectrumNumber[Incident](3),\n",
    "    isis.MonitorSpectrumNumber[Transmission]: isis.MonitorSpectrumNumber[Transmission](\n",
    "        4\n",
    "    ),\n",
    "    # Monitor names used for event files (EventWorkspace)\n",
    "    NeXusMonitorName[Incident]: NeXusMonitorName[Incident](\"monitor3\"),\n",
    "    NeXusMonitorName[Transmission]: NeXusMonitorName[Transmission](\"monitor4\"),\n",
    "    UncertaintyBroadcastMode: UncertaintyBroadcastMode.upper_bound,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ess.polarization.zoom import ZoomTransmissionFractionWorkflow\n",
    "\n",
    "sans_workflow = ZoomTransmissionFractionWorkflow(cell_runs)\n",
    "for key, value in params.items():\n",
    "    sans_workflow[key] = value\n",
    "sans_workflow[isis.mantidio.Period] = 0\n",
    "sans_workflow[Filename[EmptyBeamRun]] = str(empty_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Inspect data for one of the runs with analyzer cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = sciline.get_mapped_node_names(\n",
    "    sans_workflow, isis.mantidio.LoadedFileContents[TransmissionRun[SampleRun]]\n",
    ")\n",
    "# Load only first run\n",
    "first_run = sans_workflow.compute(loaded[0])\n",
    "sc.DataGroup(sc.collapse(first_run['data'], keep='tof')).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We can load the combined time-dependent incident and transmission monitors.\n",
    "Note that the last run is the depolarized run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mons = sans_workflow.compute(\n",
    "    (\n",
    "        NeXusComponent[Incident, TransmissionRun[SampleRun]],\n",
    "        NeXusComponent[Transmission, TransmissionRun[SampleRun]],\n",
    "    )\n",
    ")\n",
    "mons = sc.DataGroup(\n",
    "    incident=mons[NeXusComponent[Incident, TransmissionRun[SampleRun]]]['data'],\n",
    "    transmission=mons[NeXusComponent[Transmission, TransmissionRun[SampleRun]]]['data'],\n",
    ")\n",
    "display(sc.DataGroup(sc.collapse(mons['incident'], keep='tof')).plot())\n",
    "display(sc.DataGroup(sc.collapse(mons['transmission'], keep='tof')).plot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "The task graph for computing the transmission fraction is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sans_workflow.visualize(\n",
    "    TransmissionFraction[SampleRun], graph_attr={'rankdir': 'LR'}, compact=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Compute transmission fractions\n",
    "\n",
    "There are multiple files which together define the time-dependence of the analyzer cell transmission.\n",
    "Note that as before the final run (time) is the depolarized run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_transmission = sans_workflow.compute(TransmissionFraction[SampleRun])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "We can plot the computed transmission fractions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "transmission_depolarized = raw_transmission['time', -1].copy()\n",
    "transmission = raw_transmission['time', :-1].copy()\n",
    "trans = sc.DataGroup(\n",
    "    {f\"{time:c}\": transmission['time', time] for time in transmission.coords['time']}\n",
    ")\n",
    "trans['depolarized'] = transmission_depolarized\n",
    "display(trans.plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: Where can cosh yield values that can be fitted?\n",
    "transmission_empty_glass = 0.9 * sc.Unit('dimensionless')\n",
    "wavelength = sc.midpoints(transmission.coords['wavelength'])\n",
    "opacity0 = 0.8797823016804095 * sc.Unit('1/angstrom')\n",
    "(\n",
    "    sc.acosh(\n",
    "        sc.values(transmission)\n",
    "        * sc.exp(opacity0 * wavelength)\n",
    "        / transmission_empty_glass\n",
    "    )\n",
    "    / (opacity0 * wavelength)\n",
    ").plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Which wavelength bounds should be used?\n",
    "wav_min = 2.2 * sc.Unit('angstrom')\n",
    "wav_max = 2.8 * sc.Unit('angstrom')\n",
    "transmission_truncated = raw_transmission['wavelength', wav_min:wav_max]\n",
    "transmission_depolarized = transmission_truncated['time', -1].copy()\n",
    "transmission = transmission_truncated['time', :-1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "We can now setup the polarization analysis workflow.\n",
    "The previously computed transmission fractions are used as workflow inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "he3_workflow = pol.he3.He3CellWorkflow(in_situ=False, incoming_polarized=True)\n",
    "# TODO Is plus correct here, this is period 0? Do we also have minus data?\n",
    "he3_workflow[pol.he3.He3AnalyzerTransmissionFractionParallel] = transmission\n",
    "# TODO Fake empty transmission for now, would need to load different period\n",
    "he3_workflow[pol.he3.He3AnalyzerTransmissionFractionAntiParallel] = transmission[\n",
    "    'time', 0:0\n",
    "]\n",
    "he3_workflow[\n",
    "    pol.he3.He3CellTransmissionFractionIncomingUnpolarized[\n",
    "        pol.Analyzer, pol.Depolarized\n",
    "    ]\n",
    "] = transmission_depolarized\n",
    "\n",
    "# When in_situ=False, these params are used as starting guess for the fit\n",
    "he3_workflow[pol.he3.He3CellLength[pol.Analyzer]] = 0.1 * sc.Unit('m')\n",
    "he3_workflow[pol.he3.He3CellPressure[pol.Analyzer]] = 1.0 * sc.Unit('bar')\n",
    "he3_workflow[pol.he3.He3CellTemperature[pol.Analyzer]] = 300.0 * sc.Unit('K')\n",
    "\n",
    "he3_workflow[pol.he3.He3TransmissionEmptyGlass[pol.Analyzer]] = transmission_empty_glass\n",
    "he3_workflow.visualize(\n",
    "    pol.TransmissionFunction[pol.Analyzer], graph_attr={'rankdir': 'LR'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "The workflow can compute the transmission function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = he3_workflow.compute(pol.TransmissionFunction[pol.Analyzer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "We can evaluate this transmission function at desired time and wavelength points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength = sc.linspace('wavelength', start=2, stop=16.0, num=141, unit='angstrom')\n",
    "time = sc.linspace('time', start=0, stop=100000, num=101, unit='s')\n",
    "display(func.opacity_function(wavelength=wavelength).plot())\n",
    "display(func.polarization_function(time=time).plot())\n",
    "display(func(wavelength=wavelength, time=time, plus_minus='plus').plot(norm='log'))\n",
    "display(func(wavelength=wavelength, time=time, plus_minus='minus').plot(norm='log'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = sc.DataArray(\n",
    "    func(wavelength=wavelength, time=time, plus_minus='plus'),\n",
    "    coords={\n",
    "        'wavelength': wavelength,\n",
    "        'time': time,\n",
    "    },\n",
    ")\n",
    "sc.DataGroup(\n",
    "    {f\"{time:c}\": trans['time', time] for time in trans.coords['time'][::20]}\n",
    ").plot(norm='linear', linestyle='solid', marker=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = sc.DataArray(\n",
    "    func(wavelength=wavelength, time=time, plus_minus='plus'),\n",
    "    coords={\n",
    "        'wavelength': wavelength,\n",
    "        'time': time,\n",
    "    },\n",
    ")\n",
    "sc.DataGroup(\n",
    "    {f\"{wav:c}\": trans['wavelength', wav] for wav in trans.coords['wavelength'][::20]}\n",
    ").plot(norm='log', linestyle='solid', marker=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "func.opacity_function.opacity0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "func.polarization_function.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "func.polarization_function.T1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Sample data\n",
    "\n",
    "We now proceed to process the sample data.\n",
    "We use the Zoom workflow from ESSsans, configured as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sample_workflow() -> sciline.Pipeline:\n",
    "    wf = isis.zoom.ZoomWorkflow()\n",
    "    wf.insert(isis.io.transmission_from_background_run)\n",
    "    wf.insert(isis.io.transmission_from_sample_run)\n",
    "\n",
    "    # TODO Are these masks correct? Provide correct XML files!\n",
    "    masks = isis.data.zoom_tutorial_mask_filenames()\n",
    "    wf = sans.with_pixel_mask_filenames(wf, masks)\n",
    "\n",
    "    for key, value in params.items():\n",
    "        wf[key] = value\n",
    "    wf[QBins] = sc.geomspace(dim='Q', start=0.004, stop=0.8, num=141, unit='1/angstrom')\n",
    "    wf[QxBins] = sc.linspace('Qx', start=-0.4, stop=0.4, num=101, unit='1/angstrom')\n",
    "    wf[QyBins] = sc.linspace('Qy', start=-0.4, stop=0.4, num=101, unit='1/angstrom')\n",
    "    wf[NonBackgroundWavelengthRange] = sc.array(\n",
    "        dims=['wavelength'], values=[0.7, 17.1], unit='angstrom'\n",
    "    )\n",
    "    wf[CorrectForGravity] = True\n",
    "    wf[UncertaintyBroadcastMode] = UncertaintyBroadcastMode.upper_bound\n",
    "    wf[ReturnEvents] = True\n",
    "\n",
    "    # TODO Configure offsets and beam center correctly!\n",
    "    # sample_workflow[isis.SampleOffset] = sc.vector([0.0, 0.0, 0.11], unit='m')\n",
    "    # sample_workflow[isis.DetectorBankOffset] = sc.vector([0.0, 0.0, 0.5], unit='m')\n",
    "    wf[BeamCenter] = sc.vector([0.0, 0.0, 0.0], unit='m')\n",
    "\n",
    "    # TODO Use direct beam!\n",
    "    # sample_workflow[DirectBeamFilename]\n",
    "    wf[DirectBeam] = None\n",
    "\n",
    "    return wf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "The sample runs are event data, so we can simply merge all runs to obtain a single event-mode $I(Q)$.\n",
    "We use `sans.with_sample_runs` to obtain a workflow that merges the runs and computes the $I(Q)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_folder = data_folder / 'Sample_water_cell3'\n",
    "sample_runs = [str(water_folder / f'ZOOM00038{run}.nxs') for run in range(439, 466, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_workflow = make_sample_workflow()\n",
    "# TODO Is this the correct empty beam run?\n",
    "sample_workflow[Filename[EmptyBeamRun]] = str(empty_run)\n",
    "multi_run_sample_workflow = sans.with_sample_runs(sample_workflow, runs=sample_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "The sample workflow looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_run_sample_workflow.visualize(\n",
    "    IofQ[SampleRun], graph_attr={'rankdir': 'LR'}, compact=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "ESSsans does not support processing multiple periods (and there are no plans for this, as this is ISIS-specific).\n",
    "We therefore run the workflow once per period.\n",
    "Note that is is inefficient as it loads every file four times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: Running this cell takes a couple of minutes when all sample runs are used.\n",
    "\n",
    "# TODO Is this correct? We get very large times. Are we using the correct transmission\n",
    "# runs above?\n",
    "time_base = transmission.coords['datetime'].min()\n",
    "\n",
    "periods = []\n",
    "for period in range(4):\n",
    "    multi_run_sample_workflow[isis.mantidio.Period] = period\n",
    "    iofq = multi_run_sample_workflow.compute(IofQxy[SampleRun])\n",
    "    iofq = iofq.bins.assign_coords(\n",
    "        time=iofq.bins.coords['pulse_time'].to(unit=time_base.unit) - time_base\n",
    "    ).drop_coords('wavelength')  # Wavelength bounds get in the way\n",
    "    periods.append(iofq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "periods[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = sc.DataGroup({f'period {period}': periods[period] for period in range(1)})\n",
    "plopp.slicer(\n",
    "    sc.values(sc.concat(periods, 'period').hist(pulse_time=10)), keep=('Qx', 'Qy')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "## Correction workflow\n",
    "\n",
    "In the previous section we have setup the workflow for the analyzer.\n",
    "We also computed the transmission function there, but in production this will be done implicitly by running the entire workflow we will setup here.\n",
    "We can combine this with the workflow for the polarizer to obtain the full correction workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "supermirror_workflow = pol.SupermirrorWorkflow()\n",
    "supermirror_workflow.visualize(pol.TransmissionFunction[pol.Polarizer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "We will use a second-order polynomial supermirror efficiency function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ess.polarization.data import example_polarization_efficiency_table\n",
    "\n",
    "supermirror_workflow[pol.SupermirrorEfficiencyFunction[pol.Polarizer]] = (\n",
    "    pol.EfficiencyLookupTable.from_file(\n",
    "        example_polarization_efficiency_table(),\n",
    "        wavelength_colname='# X ',\n",
    "        efficiency_colname=' Y ',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = pol.PolarizationAnalysisWorkflow(\n",
    "    polarizer_workflow=supermirror_workflow,\n",
    "    analyzer_workflow=he3_workflow,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "For a single channel, the complete workflow looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.visualize(\n",
    "    pol.PolarizationCorrectedData[pol.Up, pol.Up], graph_attr={'rankdir': 'LR'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "We can now set the reduced sample data for each measured channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[pol.ReducedSampleDataBySpinChannel[pol.Up, pol.Up]] = periods[0]\n",
    "workflow[pol.ReducedSampleDataBySpinChannel[pol.Down, pol.Up]] = periods[1]\n",
    "workflow[pol.ReducedSampleDataBySpinChannel[pol.Up, pol.Down]] = periods[2]\n",
    "workflow[pol.ReducedSampleDataBySpinChannel[pol.Down, pol.Down]] = periods[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = workflow.compute(pol.PolarizationCorrectedData[pol.Up, pol.Up])\n",
    "tiled = plopp.tiled(2, 2)\n",
    "tiled[0, 0] = channels.upup.nanhist().plot()\n",
    "tiled[0, 1] = channels.updown.nanhist().plot()\n",
    "tiled[1, 0] = channels.downup.nanhist().plot()\n",
    "tiled[1, 1] = channels.downdown.nanhist().plot()\n",
    "tiled"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mantid310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
